Pythran 0.9.7 - memes tra
#########################

:date: 2020-09-23
:category: release
:lang: en
:authors: serge-sans-paille
:summary: Pythran version bump, fixing a few performance issues and benchmarking
          the release.

With version 0.9.6, Pythran introduced a new numpy expression computation engine
that solved a few issues but also introduced a performance regression for
various kernels. I've been working on fixing that aspect, and I'm quite happy
with the result, showcased in version 0.9.7.

Performance is a critical aspect of Pythran, so it comes at no surprise that the
expression evaluation engine got rewritten several times. To evaluate the
difference between 0.9.5 and 0.9.7, let's use the `numpy benchmark
<https://github.com/serge-sans-paille/numpy-benchmarks/>`_ project. It contains
a collection of high-level kernels, and was recently granted a few options to
easien comparison of performance across project version.

.. code-block:: console

    $ pip install pythran==0.9.5
    $ np-bench run -tpythran -p0.9.5- -o 095.log
    $ pip install pythran==0.9.7
    $ np-bench run -tpythran -p0.9.7- -o 097.log
    $ np-bench format 095.log 097.log -tsvg --logscale --normalize=0.9.5-pythran


Which gives:

.. image:: ./images/2020-09-23-pythran-evolve.svg


There's quite a few things to tell on that comparison: some benchmarks are in
much better shape (especially ``laplacien``, ``wave`` and ``diffusuon``) but
there's still room for improvement, as shown by ``grayscott`` and
``local_maxima``. The performance boost is due to the better expression engine,
so that's expected, but the slowdown still need some investigationâ€¦


The ``np-bench`` script also makes it possible to compare pythran with cpython
or numba. Let's try that:

.. code-block:: console

    $ pip install -U pythran numba
    $ np-bench run -tpythran -tnumba -tpython -oall.log
    $ np-bench format all.log -tsvg --logscale --normalize=python

Which gives:

.. image:: ./images/2020-09-23-pythran-all.svg

Interestingly, unoptimized python is still ahead for a few benchmarks, that
prove to be too complex to optimize (?) Another subject that needs
investigation.

The kernel are mostly high-level ones, and that doesn't always match numba's
reuqirements, which explains that it sometimes just scoops.

Overall Pythran performance are still satisfying, but we definitily need to
investigate why we lost performance compared to 0.9.5 in a few cases, and why we
don't manage to generate faster code for ``peridoic-dist`` and ``cronbach``.

And if you're interested in investigating the benchmarks, all source are
available in
https://github.com/serge-sans-paille/numpy-benchmarks/tree/master/numpy_benchmarks/benchmarks
